{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.10.0+cu130\n",
      "Device:  cuda\n",
      "Train images:  Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: .data/\n",
      "    Split: Train\n",
      "Image:  <PIL.Image.Image image mode=L size=28x28 at 0x2A4841D52B0>\n",
      "Label:  5\n",
      "Label one hot:  tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "\n",
      "Loading MNIST  train  Dataset...\n",
      "\tTotal Len.:  60000 \n",
      " --------------------------------------------------\n",
      "\n",
      "Loading MNIST  test  Dataset...\n",
      "\tTotal Len.:  10000 \n",
      " --------------------------------------------------\n",
      "Num workers 0\n",
      "Net(\n",
      "  (linear1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (BatchNorm1d1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.2, inplace=False)\n",
      "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (BatchNorm1d2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (linear3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (BatchNorm1d3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (drop3): Dropout(p=0.4, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Params:  569226\n",
      "\n",
      "---- Start Training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 600/600 [00:06<00:00, 97.99batch/s] \n",
      "Test 0: 100%|██████████| 100/100 [00:00<00:00, 112.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.008315 - Test Loss: 0.002893 - Train Accuracy: 78.08% - Test Accuracy: 92.80%\n",
      "EarlyStopping: best=92.80% (epoch 1) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 600/600 [00:06<00:00, 99.29batch/s] \n",
      "Test 1: 100%|██████████| 100/100 [00:00<00:00, 111.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.003520 - Test Loss: 0.001836 - Train Accuracy: 90.56% - Test Accuracy: 94.88%\n",
      "EarlyStopping: best=94.88% (epoch 2) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 600/600 [00:06<00:00, 99.58batch/s] \n",
      "Test 2: 100%|██████████| 100/100 [00:00<00:00, 112.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.002640 - Test Loss: 0.001445 - Train Accuracy: 92.63% - Test Accuracy: 95.76%\n",
      "EarlyStopping: best=95.76% (epoch 3) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 600/600 [00:06<00:00, 99.85batch/s] \n",
      "Test 3: 100%|██████████| 100/100 [00:00<00:00, 112.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.002231 - Test Loss: 0.001225 - Train Accuracy: 93.68% - Test Accuracy: 96.36%\n",
      "EarlyStopping: best=96.36% (epoch 4) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 600/600 [00:05<00:00, 100.04batch/s]\n",
      "Test 4: 100%|██████████| 100/100 [00:00<00:00, 110.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.001906 - Test Loss: 0.001085 - Train Accuracy: 94.59% - Test Accuracy: 96.75%\n",
      "EarlyStopping: best=96.75% (epoch 5) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 600/600 [00:06<00:00, 93.14batch/s]\n",
      "Test 5: 100%|██████████| 100/100 [00:00<00:00, 102.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.001700 - Test Loss: 0.000965 - Train Accuracy: 95.15% - Test Accuracy: 97.11%\n",
      "EarlyStopping: best=97.11% (epoch 6) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 600/600 [00:06<00:00, 94.52batch/s]\n",
      "Test 6: 100%|██████████| 100/100 [00:00<00:00, 103.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.001581 - Test Loss: 0.000886 - Train Accuracy: 95.45% - Test Accuracy: 97.27%\n",
      "EarlyStopping: best=97.27% (epoch 7) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 600/600 [00:06<00:00, 94.11batch/s]\n",
      "Test 7: 100%|██████████| 100/100 [00:00<00:00, 105.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.001436 - Test Loss: 0.000829 - Train Accuracy: 95.88% - Test Accuracy: 97.47%\n",
      "EarlyStopping: best=97.47% (epoch 8) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 600/600 [00:06<00:00, 94.15batch/s]\n",
      "Test 8: 100%|██████████| 100/100 [00:00<00:00, 105.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.001321 - Test Loss: 0.000764 - Train Accuracy: 96.12% - Test Accuracy: 97.63%\n",
      "EarlyStopping: best=97.63% (epoch 9) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 600/600 [00:06<00:00, 94.70batch/s]\n",
      "Test 9: 100%|██████████| 100/100 [00:00<00:00, 106.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.001226 - Test Loss: 0.000758 - Train Accuracy: 96.49% - Test Accuracy: 97.61%\n",
      "EarlyStopping: best=97.63% (epoch 9) patience_counter=1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 600/600 [00:06<00:00, 95.02batch/s]\n",
      "Test 10: 100%|██████████| 100/100 [00:00<00:00, 105.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.001142 - Test Loss: 0.000716 - Train Accuracy: 96.72% - Test Accuracy: 97.78%\n",
      "EarlyStopping: best=97.78% (epoch 11) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 600/600 [00:06<00:00, 95.07batch/s]\n",
      "Test 11: 100%|██████████| 100/100 [00:00<00:00, 105.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.001041 - Test Loss: 0.000683 - Train Accuracy: 96.95% - Test Accuracy: 97.86%\n",
      "EarlyStopping: best=97.78% (epoch 11) patience_counter=1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 600/600 [00:06<00:00, 93.51batch/s]\n",
      "Test 12: 100%|██████████| 100/100 [00:00<00:00, 106.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.001005 - Test Loss: 0.000650 - Train Accuracy: 97.10% - Test Accuracy: 97.98%\n",
      "EarlyStopping: best=97.98% (epoch 13) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 600/600 [00:06<00:00, 92.33batch/s]\n",
      "Test 13: 100%|██████████| 100/100 [00:00<00:00, 105.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.000956 - Test Loss: 0.000603 - Train Accuracy: 97.18% - Test Accuracy: 98.18%\n",
      "EarlyStopping: best=98.18% (epoch 14) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 600/600 [00:06<00:00, 93.98batch/s]\n",
      "Test 14: 100%|██████████| 100/100 [00:00<00:00, 102.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 0.000919 - Test Loss: 0.000627 - Train Accuracy: 97.31% - Test Accuracy: 97.99%\n",
      "EarlyStopping: best=98.18% (epoch 14) patience_counter=1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 600/600 [00:06<00:00, 91.61batch/s]\n",
      "Test 15: 100%|██████████| 100/100 [00:00<00:00, 104.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.000879 - Test Loss: 0.000600 - Train Accuracy: 97.36% - Test Accuracy: 98.12%\n",
      "EarlyStopping: best=98.18% (epoch 14) patience_counter=2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 600/600 [00:06<00:00, 91.73batch/s]\n",
      "Test 16: 100%|██████████| 100/100 [00:00<00:00, 103.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.000807 - Test Loss: 0.000589 - Train Accuracy: 97.64% - Test Accuracy: 98.16%\n",
      "EarlyStopping: best=98.18% (epoch 14) patience_counter=3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 600/600 [00:06<00:00, 94.78batch/s]\n",
      "Test 17: 100%|██████████| 100/100 [00:00<00:00, 104.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.000783 - Test Loss: 0.000574 - Train Accuracy: 97.66% - Test Accuracy: 98.25%\n",
      "EarlyStopping: best=98.18% (epoch 14) patience_counter=4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 600/600 [00:06<00:00, 89.65batch/s]\n",
      "Test 18: 100%|██████████| 100/100 [00:00<00:00, 101.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.000766 - Test Loss: 0.000580 - Train Accuracy: 97.68% - Test Accuracy: 98.13%\n",
      "EarlyStopping: best=98.18% (epoch 14) patience_counter=5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 600/600 [00:06<00:00, 90.28batch/s]\n",
      "Test 19: 100%|██████████| 100/100 [00:01<00:00, 97.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.000730 - Test Loss: 0.000550 - Train Accuracy: 97.81% - Test Accuracy: 98.29%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 600/600 [00:06<00:00, 86.61batch/s]\n",
      "Test 20: 100%|██████████| 100/100 [00:01<00:00, 98.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 0.000686 - Test Loss: 0.000555 - Train Accuracy: 97.96% - Test Accuracy: 98.22%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 600/600 [00:06<00:00, 91.51batch/s]\n",
      "Test 21: 100%|██████████| 100/100 [00:00<00:00, 104.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 0.000681 - Test Loss: 0.000555 - Train Accuracy: 97.91% - Test Accuracy: 98.32%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 600/600 [00:06<00:00, 93.95batch/s]\n",
      "Test 22: 100%|██████████| 100/100 [00:00<00:00, 105.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 0.000661 - Test Loss: 0.000537 - Train Accuracy: 98.00% - Test Accuracy: 98.26%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 600/600 [00:06<00:00, 94.03batch/s]\n",
      "Test 23: 100%|██████████| 100/100 [00:00<00:00, 105.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 0.000631 - Test Loss: 0.000545 - Train Accuracy: 98.18% - Test Accuracy: 98.38%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 600/600 [00:06<00:00, 93.35batch/s]\n",
      "Test 24: 100%|██████████| 100/100 [00:00<00:00, 103.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Loss: 0.000607 - Test Loss: 0.000554 - Train Accuracy: 98.22% - Test Accuracy: 98.15%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 600/600 [00:06<00:00, 93.99batch/s]\n",
      "Test 25: 100%|██████████| 100/100 [00:00<00:00, 106.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train Loss: 0.000610 - Test Loss: 0.000543 - Train Accuracy: 98.12% - Test Accuracy: 98.36%\n",
      "EarlyStopping: best=98.29% (epoch 20) patience_counter=6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 600/600 [00:06<00:00, 94.04batch/s]\n",
      "Test 26: 100%|██████████| 100/100 [00:00<00:00, 104.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Loss: 0.000551 - Test Loss: 0.000531 - Train Accuracy: 98.36% - Test Accuracy: 98.41%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 600/600 [00:06<00:00, 93.82batch/s]\n",
      "Test 27: 100%|██████████| 100/100 [00:00<00:00, 102.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train Loss: 0.000569 - Test Loss: 0.000533 - Train Accuracy: 98.27% - Test Accuracy: 98.35%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 600/600 [00:06<00:00, 90.83batch/s]\n",
      "Test 28: 100%|██████████| 100/100 [00:00<00:00, 100.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train Loss: 0.000509 - Test Loss: 0.000543 - Train Accuracy: 98.41% - Test Accuracy: 98.32%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 600/600 [00:07<00:00, 80.46batch/s]\n",
      "Test 29: 100%|██████████| 100/100 [00:00<00:00, 105.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train Loss: 0.000510 - Test Loss: 0.000520 - Train Accuracy: 98.44% - Test Accuracy: 98.36%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 600/600 [00:06<00:00, 93.43batch/s]\n",
      "Test 30: 100%|██████████| 100/100 [00:00<00:00, 105.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Train Loss: 0.000519 - Test Loss: 0.000516 - Train Accuracy: 98.39% - Test Accuracy: 98.44%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 600/600 [00:06<00:00, 92.03batch/s]\n",
      "Test 31: 100%|██████████| 100/100 [00:01<00:00, 94.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train Loss: 0.000469 - Test Loss: 0.000531 - Train Accuracy: 98.52% - Test Accuracy: 98.41%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 600/600 [00:06<00:00, 91.42batch/s]\n",
      "Test 32: 100%|██████████| 100/100 [00:00<00:00, 103.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Train Loss: 0.000493 - Test Loss: 0.000528 - Train Accuracy: 98.45% - Test Accuracy: 98.37%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 600/600 [00:06<00:00, 89.88batch/s]\n",
      "Test 33: 100%|██████████| 100/100 [00:00<00:00, 102.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Train Loss: 0.000455 - Test Loss: 0.000520 - Train Accuracy: 98.60% - Test Accuracy: 98.40%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 600/600 [00:06<00:00, 92.75batch/s]\n",
      "Test 34: 100%|██████████| 100/100 [00:00<00:00, 102.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Train Loss: 0.000427 - Test Loss: 0.000497 - Train Accuracy: 98.69% - Test Accuracy: 98.43%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 600/600 [00:06<00:00, 94.15batch/s]\n",
      "Test 35: 100%|██████████| 100/100 [00:00<00:00, 105.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Train Loss: 0.000453 - Test Loss: 0.000532 - Train Accuracy: 98.55% - Test Accuracy: 98.38%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 600/600 [00:06<00:00, 87.05batch/s]\n",
      "Test 36: 100%|██████████| 100/100 [00:00<00:00, 103.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Train Loss: 0.000440 - Test Loss: 0.000488 - Train Accuracy: 98.62% - Test Accuracy: 98.43%\n",
      "EarlyStopping: best=98.41% (epoch 27) patience_counter=10/10\n",
      "Stopping early at epoch 37. Best was epoch 27 with acc 98.41%\n",
      "\n",
      "BEST TEST ACCURACY:  98.44  in epoch  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test 36: 100%|██████████| 100/100 [00:00<00:00, 105.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final best acc:  98.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as  F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"Torch version: \", torch. __version__)\n",
    "\n",
    "####################################################################\n",
    "# Set Device\n",
    "####################################################################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Prepare Data\n",
    "####################################################################\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('.data/', train=True, download=True)\n",
    "#? Considera usar transform=transforms.Compose([ToTensor(), Normalize((0.1307,), (0.3081,))]) para centrar/escala antes del flatten.\n",
    "#train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('.data/', train=False, download=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Train images: \", train_set)\n",
    "print(\"Image: \", train_set[0][0])\n",
    "print(\"Label: \", train_set[0][1])\n",
    "print(\"Label one hot: \", F.one_hot(torch.tensor(train_set[0][1]), num_classes=10))\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Dataset Class\n",
    "####################################################################\n",
    "\n",
    "class MNIST_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, partition = \"train\"):\n",
    "\n",
    "        print(\"\\nLoading MNIST \", partition, \" Dataset...\")\n",
    "        self.data = data\n",
    "        self.partition = partition\n",
    "        print(\"\\tTotal Len.: \", len(self.data), \"\\n\", 50*\"-\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def from_pil_to_tensor(self, image):\n",
    "        return torchvision.transforms.ToTensor()(image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Image\n",
    "        image = self.data[idx][0]\n",
    "        # PIL Image to torch tensor\n",
    "        image_tensor = self.from_pil_to_tensor(image)\n",
    "        # care! net expect a 784 size vector and our dataset\n",
    "        # provide 1x28x28 (channels, height, width) -> Reshape!\n",
    "        image_tensor = image_tensor.view(-1)\n",
    "#? Tambien puedes normalizar aqui (image_tensor = (image_tensor - mean) / std) si no usas transforms.\n",
    "\n",
    "        # Label\n",
    "        label = torch.tensor(self.data[idx][1])\n",
    "        label = F.one_hot(label, num_classes=10).float()\n",
    "#? Alternativa: devuelve label como entero y usa CrossEntropyLoss(label_smoothing=0.1) para regularizar sin one-hot.\n",
    "\n",
    "        return {\"img\": image_tensor, \"label\": label}\n",
    "\n",
    "train_dataset = MNIST_dataset(train_set, partition=\"train\")\n",
    "test_dataset = MNIST_dataset(test_set, partition=\"test\")\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# DataLoader Class\n",
    "####################################################################\n",
    "\n",
    "batch_size = 100\n",
    "num_workers = 0\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "#? Para GPU ayuda pin_memory=True y persistent_workers=True cuando num_workers>0.\n",
    "\n",
    "####################################################################\n",
    "# Early stopping Class\n",
    "####################################################################\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode=\"max\"):\n",
    "        \"\"\"\n",
    "        patience: nº de epochs sin mejora para parar\n",
    "        min_delta: mejora mínima para considerar 'mejora real'\n",
    "        mode: \"max\" si monitorizas accuracy, \"min\" si monitorizas loss\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.best_state_dict = None\n",
    "        self.best_epoch = -1\n",
    "\n",
    "    def step(self, score, model, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_state_dict = copy.deepcopy(model.state_dict())\n",
    "            self.best_epoch = epoch\n",
    "            return False  # no parar\n",
    "\n",
    "        improved = (score > self.best_score + self.min_delta) if self.mode == \"max\" \\\n",
    "                   else (score < self.best_score - self.min_delta)\n",
    "\n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.best_state_dict = copy.deepcopy(model.state_dict())\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        return self.counter >= self.patience  # True => parar\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Neural Network Class\n",
    "####################################################################\n",
    "\n",
    "# Creating our Neural Network - Fully Connected\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        #* AÑADIDO CAPA BATCHNORM1D Y DROPOUT\n",
    "        self.linear1 = nn.Linear(784, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.BatchNorm1d1 = nn.BatchNorm1d(512)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.BatchNorm1d2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.BatchNorm1d3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(0.4)\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "#? BatchNorm1d tras cada Linear y Dropout(0.1-0.3) antes de la activacion suelen mejorar la generalizacion.\n",
    "#? Un MLP mas profundo pero mas estrecho (ej. 784->512->256->128->10) reduce parametros y overfitting sin usar CNN.\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop1(self.relu1(self.BatchNorm1d1(self.linear1(x))))\n",
    "        out = self.drop2(self.relu2(self.BatchNorm1d2(self.linear2(out))))\n",
    "        out = self.drop3(self.relu3(self.BatchNorm1d3(self.linear3(out))))\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = Net(num_classes)\n",
    "print(net)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(net))\n",
    "\n",
    "####################################################################\n",
    "# Training settings\n",
    "####################################################################\n",
    "\n",
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, weight_decay=1e-6, momentum=0.9) # Original lr=0.01\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "epochs = 75 # Original = 25\n",
    "#? Prueba AdamW con weight_decay mas alto (p.ej. 1e-2) y un scheduler CosineAnnealingLR u OneCycleLR.\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Training\n",
    "####################################################################\n",
    "\n",
    "# Load model in GPU\n",
    "net.to(device)\n",
    "\n",
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "best_epoch = 0\n",
    "\n",
    "early_stopper = EarlyStopping(patience=10, min_delta=0.1, mode=\"max\")\n",
    "# min_delta=0.05 significa +0.05% de accuracy como mejora mínima (ajústalo si quieres)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    # TRAIN NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    with tqdm(iter(train_dataloader), desc=\"Epoch \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "\n",
    "            # Returned values of Dataset Class\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "#? Puedes recortar gradientes con torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0) si ves inestabilidad.\n",
    "\n",
    "            # Update gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # one hot -> labels\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            train_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "            # print statistics\n",
    "            train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    test_loss, test_correct = 0, 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "          for batch in tepoch:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = net(images)\n",
    "            test_loss += criterion(outputs, labels)\n",
    "\n",
    "            # one hot -> labels\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            test_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\n",
    "\n",
    "    print(\"[Epoch {}] Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n",
    "        epoch + 1, train_loss, test_loss, 100. * train_correct / len(train_dataloader.dataset), test_accuracy\n",
    "    ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_epoch = epoch\n",
    "\n",
    "        # Save best weights\n",
    "        torch.save(net.state_dict(), \"best_model.pt\")\n",
    "        \n",
    "    should_stop = early_stopper.step(test_accuracy, net, epoch)\n",
    "    print(f\"EarlyStopping: best={early_stopper.best_score:.2f}% (epoch {early_stopper.best_epoch+1}) \"\n",
    "        f\"patience_counter={early_stopper.counter}/{early_stopper.patience}\")\n",
    "\n",
    "    if should_stop:\n",
    "        print(f\"Stopping early at epoch {epoch+1}. Best was epoch {early_stopper.best_epoch+1} \"\n",
    "            f\"with acc {early_stopper.best_score:.2f}%\")\n",
    "        break\n",
    "\n",
    "#? Agrega early stopping con paciencia (p.ej. 10 epocas) y ReduceLROnPlateau para bajar lr cuando el val loss se estanque.\n",
    "\n",
    "print(\"\\nBEST TEST ACCURACY: \", best_accuracy, \" in epoch \", best_epoch)\n",
    "\n",
    "# So far:\n",
    "# best acc:  98.24 (default)\n",
    "# best acc:  96.64 with lr: 0.001\n",
    "# best acc:  98.26 with 2 hidden layers\n",
    "# best acc:  98.64 with lr: 0.1\n",
    "# best acc:  98.02 with lr: 0.001 & 75 epochs\n",
    "\n",
    "####################################################################\n",
    "# Load best weights\n",
    "####################################################################\n",
    "\n",
    "# Load best weights\n",
    "net.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "test_loss, test_correct = 0, 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = net(images)\n",
    "            test_loss += criterion(outputs, labels)\n",
    "\n",
    "            # one hot -> labels\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            test_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\n",
    "print(\"Final best acc: \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
